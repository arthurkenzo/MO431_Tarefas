{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet e bibliotecas a serem usados no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timeStamp\n",
      "0     196      242       3  881250949\n",
      "1     186      302       3  891717742\n",
      "2      22      377       1  878887116\n",
      "3     244       51       2  880606923\n",
      "4     166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax as jax\n",
    "from typing import Callable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# user id | item id | rating | timestamp.\n",
    "_df = pd.read_csv('ml-100k/u.data', delimiter='\\t', header=None, names=['userId', 'movieId', 'rating', 'timeStamp'])\n",
    "print(_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados: transposição em matriz, preenchimento de dados faltantes, normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "userId                                                               ...   \n",
      "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
      "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "\n",
      "movieId  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "userId                                                               \n",
      "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 1682 columns] \n",
      "\n",
      "Novo formato do DataFrame:  (943, 1682) \n",
      "\n",
      "DataFrame with column mean filled:\n",
      " movieId      1         2         3         4         5         6         7     \\\n",
      "userId                                                                          \n",
      "1        5.000000  3.000000  4.000000  3.000000  3.000000  5.000000  4.000000   \n",
      "2        4.000000  3.206107  3.033333  3.550239  3.302326  3.576923  3.798469   \n",
      "3        3.878319  3.206107  3.033333  3.550239  3.302326  3.576923  3.798469   \n",
      "4        3.878319  3.206107  3.033333  3.550239  3.302326  3.576923  3.798469   \n",
      "5        4.000000  3.000000  3.033333  3.550239  3.302326  3.576923  3.798469   \n",
      "\n",
      "movieId      8         9         10    ...  1673  1674  1675  1676  1677  \\\n",
      "userId                                 ...                                 \n",
      "1        1.000000  5.000000  3.000000  ...   3.0   4.0   3.0   2.0   3.0   \n",
      "2        3.995434  3.896321  2.000000  ...   3.0   4.0   3.0   2.0   3.0   \n",
      "3        3.995434  3.896321  3.831461  ...   3.0   4.0   3.0   2.0   3.0   \n",
      "4        3.995434  3.896321  3.831461  ...   3.0   4.0   3.0   2.0   3.0   \n",
      "5        3.995434  3.896321  3.831461  ...   3.0   4.0   3.0   2.0   3.0   \n",
      "\n",
      "movieId  1678  1679  1680  1681  1682  \n",
      "userId                                 \n",
      "1         1.0   3.0   2.0   3.0   3.0  \n",
      "2         1.0   3.0   2.0   3.0   3.0  \n",
      "3         1.0   3.0   2.0   3.0   3.0  \n",
      "4         1.0   3.0   2.0   3.0   3.0  \n",
      "5         1.0   3.0   2.0   3.0   3.0  \n",
      "\n",
      "[5 rows x 1682 columns] \n",
      "\n",
      "DataFrame with row mean filled:\n",
      " movieId      1         2         3         4         5         6         7     \\\n",
      "userId                                                                          \n",
      "1        5.000000  3.000000  4.000000  3.000000  3.000000  5.000000  4.000000   \n",
      "2        4.000000  3.709677  3.709677  3.709677  3.709677  3.709677  3.709677   \n",
      "3        2.796296  2.796296  2.796296  2.796296  2.796296  2.796296  2.796296   \n",
      "4        4.333333  4.333333  4.333333  4.333333  4.333333  4.333333  4.333333   \n",
      "5        4.000000  3.000000  2.874286  2.874286  2.874286  2.874286  2.874286   \n",
      "\n",
      "movieId      8         9         10    ...      1673      1674      1675  \\\n",
      "userId                                 ...                                 \n",
      "1        1.000000  5.000000  3.000000  ...  3.610294  3.610294  3.610294   \n",
      "2        3.709677  3.709677  2.000000  ...  3.709677  3.709677  3.709677   \n",
      "3        2.796296  2.796296  2.796296  ...  2.796296  2.796296  2.796296   \n",
      "4        4.333333  4.333333  4.333333  ...  4.333333  4.333333  4.333333   \n",
      "5        2.874286  2.874286  2.874286  ...  2.874286  2.874286  2.874286   \n",
      "\n",
      "movieId      1676      1677      1678      1679      1680      1681      1682  \n",
      "userId                                                                         \n",
      "1        3.610294  3.610294  3.610294  3.610294  3.610294  3.610294  3.610294  \n",
      "2        3.709677  3.709677  3.709677  3.709677  3.709677  3.709677  3.709677  \n",
      "3        2.796296  2.796296  2.796296  2.796296  2.796296  2.796296  2.796296  \n",
      "4        4.333333  4.333333  4.333333  4.333333  4.333333  4.333333  4.333333  \n",
      "5        2.874286  2.874286  2.874286  2.874286  2.874286  2.874286  2.874286  \n",
      "\n",
      "[5 rows x 1682 columns] \n",
      "\n",
      "DataFrame with zeros filled:\n",
      " movieId  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "userId                                                               ...   \n",
      "1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
      "2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n",
      "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "5         4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "movieId  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "userId                                                               \n",
      "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 1682 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convertendo a lista de dados em uma tabela com usuários nas linhas, filmes na colunas, contendo os ratings correspondentes.\n",
    "df = _df.pivot(index='userId', columns='movieId', values='rating')\n",
    "print(df.head(), '\\n')\n",
    "print(\"Novo formato do DataFrame: \", df.shape, '\\n')\n",
    "\n",
    "# Preenchendo valores faltantes com o rating médio do filme correspondente\n",
    "dfMovieMean = df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# Preenchendo valores faltantes com a média dos ratings dados pelo usuário\n",
    "dfUserMean = df.apply(lambda x: x.fillna(x.mean()), axis=1)\n",
    "\n",
    "# Preenchendo valroes faltantes com zeros\n",
    "dfZeros = df.fillna(0)\n",
    "\n",
    "print(\"DataFrame with column mean filled:\\n\", dfMovieMean.head(), '\\n')\n",
    "print(\"DataFrame with row mean filled:\\n\", dfUserMean.head(), '\\n')\n",
    "print(\"DataFrame with zeros filled:\\n\", dfZeros.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação dos dados de treino e teste, normalização e conversão para arrays de JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(data:jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Normaliza dados de um array subtraindo médias normalizando em relação ao desvio padrão de cada feature.\n",
    "\n",
    "    Args:\n",
    "        data (jnp.ndarray): Dados não normalizdos\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: Dados normalizados\n",
    "    \"\"\"\n",
    "    #Normalizando os dados: subtração da média de cada feature e mapeando para o intervalo [0,1]\n",
    "    means = jnp.mean(data, axis=0)\n",
    "    normalizedData = data - means\n",
    "\n",
    "    std = jnp.std(normalizedData, axis=0)\n",
    "    normalizedData = normalizedData / std\n",
    "    \n",
    "    return normalizedData\n",
    "\n",
    "# Separando dados de treino e de teste\n",
    "features = dfZeros.columns.tolist()[:-1]\n",
    "x = dfZeros[[feature for feature in features]]  \n",
    "y = dfZeros['target']  \n",
    "\n",
    "# Normalizando os dados. Como a função de normalização funciona com JAX, \n",
    "# mas a separação dos conjuntos de teste e treino é feita pelo scikit-learn, precisei fazer duas conversões entre tipos.\n",
    "x = normalizeData(jnp.array(x.values))\n",
    "x = pd.DataFrame(x)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Convertendo para arrays compatíveis com JAX:\n",
    "xTrain = jnp.array(xTrain)\n",
    "xTest = jnp.array(xTest)\n",
    "yTrain = jnp.array(yTrain)\n",
    "yTest = jnp.array(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo as funções para implementação do PCA e KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(data:jnp.ndarray, nbComponents:int, svd=True) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    A partir de um conjunto de dados, retorna a matriz de projeção para as k componentes principais.\n",
    "\n",
    "    Args:\n",
    "        data (jnp.ndaaray): Dados para reduzir dimensionalidade.\n",
    "        nbComponents (int): Número de componentes desejadas na projeção.\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: Matriz de projeção.\n",
    "    \"\"\"\n",
    "\n",
    "    covarianceMatrix = (1/len(data)) * data.T @ data\n",
    "    \n",
    "    if svd:\n",
    "        # Realizando a decomposição em valores singulares. U terá vetores coluna ortogonais.  \n",
    "        # A pricípio, o ordenamento não é necessário pois svd() já retorna os valores singulares ordenados.  \n",
    "        U, S, Ut = jax.scipy.linalg.svd(covarianceMatrix) \n",
    "        projectionMatrix = U[:, :nbComponents]\n",
    "    else:\n",
    "        # Decomposição a partir de autovalores e autovetores.\n",
    "        # Aqui, o ordenamento dos autovetores baseado nos autovalores é necessário.\n",
    "        eigenvalues, eigenvectors = jnp.linalg.eig(covarianceMatrix)  \n",
    "        indices = jnp.argsort(eigenvalues, descending=True)           \n",
    "        projectionMatrix = eigenvectors[:, indices]  \n",
    "        projectionMatrix = projectionMatrix[:, :nbComponents]\n",
    "   \n",
    "\n",
    "    return projectionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(xTrain:jnp.ndarray, yTrain:jnp.ndarray, xTest:jnp.ndarray, k:int, metric:Callable[[jnp.ndarray, jnp.ndarray], float]) -> jnp.ndarray:\n",
    "    \"\"\" Implementa a classificação de um conjunto de dados a partir do algoritmo de K-Nearest Neighbors (KNN).\n",
    "\n",
    "    Args:\n",
    "        xTrain (jnp.ndarray): Dados de treino\n",
    "        yTrain (jnp.ndarray): Labels para os dados de treino\n",
    "        xTest (jnp.ndarray): Dados de teste\n",
    "        k (int): Número de vizinhos mais próximos usados para a classificação.\n",
    "        metric (Callable): Função que calcula distância entre dois pontos.\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: Array contendo as predições realizadas para o conjunto de dados de teste xTest.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Implementação JAX-friendly do cálculo da matriz de distâncias para um conjunto de pontos de teste.\n",
    "    # O cálculo da matriz é feito vetorizando duas vezes a função de métrica, para calcular dois a dois\n",
    "    # as distâncias entre pontos de treino e de teste.\n",
    "    distances = jax.vmap(lambda train_point: jax.vmap(metric, in_axes=(None, 0))(train_point, xTest))(xTrain)\n",
    "\n",
    "    # Ordenando as distâncias entre pontos, e pegando os targets/labels dos k pontos mais próximos para cada ponto de treino\n",
    "    sorted_indices = jnp.argsort(distances, axis=0)\n",
    "    nearestNeighborsIndices = sorted_indices[:k, :]\n",
    "    nearestNeighbors = yTrain[nearestNeighborsIndices].astype(int)\n",
    "\n",
    "    # Contagem dos números de cada target presente na lista de vizinhos próximos e definição do target estimado para o ponto\n",
    "    # de teste baseado numa voto de maioria.\n",
    "    totalLabels = 3\n",
    "    targetCounts = jax.vmap(lambda neighbors: jnp.bincount(neighbors, minlength=totalLabels, length=3))(nearestNeighbors.T) \n",
    "    most_common_classes = jnp.argmax(targetCounts, axis=1)\n",
    "    \n",
    "    return most_common_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mo431",
   "language": "python",
   "name": "mo431"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
