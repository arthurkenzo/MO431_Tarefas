{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet e bibliotecas a serem usados no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timeStamp\n",
      "0     196      242       3  881250949\n",
      "1     186      302       3  891717742\n",
      "2      22      377       1  878887116\n",
      "3     244       51       2  880606923\n",
      "4     166      346       1  886397596 \n",
      " (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax as jax\n",
    "from typing import Callable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# user id | item id | rating | timestamp.\n",
    "_df = pd.read_csv('ml-100k/u.data', delimiter='\\t', header=None, names=['userId', 'movieId', 'rating', 'timeStamp'])\n",
    "originalData = _df.pivot(index='userId', columns='movieId', values='rating')\n",
    "print(_df.head(), \"\\n\", originalData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação de dados de teste\n",
    "\n",
    "De acordo com a documentação, os dados já estão ordenados de maneira aleatória, então podemos apenas pegar os primeiros 20% de entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = _df[:int(0.2*len(_df))]\n",
    "_df = _df[int(0.2*len(_df)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados: transposição em matriz, preenchimento de dados faltantes, normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
      "userId                                                               ...   \n",
      "1         5.0   3.0   4.0   3.0   3.0   NaN   4.0   1.0   5.0   NaN  ...   \n",
      "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "\n",
      "movieId  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
      "userId                                                               \n",
      "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 1682 columns] \n",
      "\n",
      "Novo formato do DataFrame de treino:  (943, 1682) \n",
      "\n",
      "Novo formato do DataFrame de teste:  (943, 1682) \n",
      "\n",
      "DataFrame with column mean filled:\n",
      " movieId     1         2     3         4         5     6         7        8     \\\n",
      "userId                                                                          \n",
      "1        5.00000  3.000000   4.0  3.000000  3.000000   3.4  4.000000  1.00000   \n",
      "2        4.00000  3.180952   3.0  3.526316  3.304348   3.4  3.798046  3.99422   \n",
      "3        3.89295  3.180952   3.0  3.526316  3.304348   3.4  3.798046  3.99422   \n",
      "4        3.89295  3.180952   3.0  3.526316  3.304348   3.4  3.798046  3.99422   \n",
      "5        3.89295  3.180952   3.0  3.526316  3.304348   3.4  3.798046  3.99422   \n",
      "\n",
      "movieId      9         10    ...  1673  1674  1675  1676  1677  1678  1679  \\\n",
      "userId                       ...                                             \n",
      "1        5.000000  3.876712  ...   3.0   4.0   3.0   2.0   3.0   1.0   3.0   \n",
      "2        3.833333  2.000000  ...   3.0   4.0   3.0   2.0   3.0   1.0   3.0   \n",
      "3        3.833333  3.876712  ...   3.0   4.0   3.0   2.0   3.0   1.0   3.0   \n",
      "4        3.833333  3.876712  ...   3.0   4.0   3.0   2.0   3.0   1.0   3.0   \n",
      "5        3.833333  3.876712  ...   3.0   4.0   3.0   2.0   3.0   1.0   3.0   \n",
      "\n",
      "movieId  1680  1681  1682  \n",
      "userId                     \n",
      "1         2.0   3.0   3.0  \n",
      "2         2.0   3.0   3.0  \n",
      "3         2.0   3.0   3.0  \n",
      "4         2.0   3.0   3.0  \n",
      "5         2.0   3.0   3.0  \n",
      "\n",
      "[5 rows x 1682 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convertendo a lista de dados em uma tabela com usuários nas linhas, filmes nas colunas, contendo os ratings correspondentes.\n",
    "trainData = _df.pivot(index='userId', columns='movieId', values='rating')\n",
    "testData = testData.pivot(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# Reindexando os dataframes separados para incluuir todos os userIds e movieIds do dataframe original\n",
    "userIds = [_ for _ in range(1,944)]\n",
    "movieIds = [_ for _ in range(1,1683)]\n",
    "trainData = trainData.reindex(index=userIds, columns=movieIds)\n",
    "testData = testData.reindex(index=userIds, columns=movieIds)\n",
    "\n",
    "\n",
    "print(trainData.head(), '\\n')\n",
    "print(\"Novo formato do DataFrame de treino: \", trainData.shape, '\\n')\n",
    "print(\"Novo formato do DataFrame de teste: \", testData.shape, '\\n')\n",
    "\n",
    "# Preenchendo valores faltantes com o rating médio do filme correspondente\n",
    "trainDataFilled = trainData.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "print(\"DataFrame with column mean filled:\\n\", trainDataFilled.head(), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.8474478e+00, -5.4083842e-01,  2.8511946e+00, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [ 1.7864378e-01, -1.4251887e-06,  0.0000000e+00, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [-1.1936216e-06, -1.4251887e-06,  0.0000000e+00, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       ...,\n",
       "       [ 1.8474478e+00, -1.4251887e-06,  0.0000000e+00, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [-1.1936216e-06, -1.4251887e-06,  0.0000000e+00, ...,\n",
       "                   nan,            nan,            nan],\n",
       "       [-1.1936216e-06,  5.4368358e+00,  0.0000000e+00, ...,\n",
       "                   nan,            nan,            nan]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeData(data:jnp.ndarray) -> tuple[jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Normaliza dados de um array subtraindo médias normalizando em relação ao desvio padrão \n",
    "    de cada feature.\n",
    "\n",
    "    Args:\n",
    "        data (jnp.ndarray): Dados não normalizdos\n",
    "        \n",
    "    Returns:\n",
    "        tuple[jnp.ndarray, jnp.ndarray]: Dados normalizados de treino e teste\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalizando os dados: subtração da média de cada feature e mapeando para o intervalo [0,1]\n",
    "    mean = jnp.nanmean(data, axis=0)\n",
    "    std = jnp.nanstd(data, axis=0)\n",
    "\n",
    "    data = data - mean\n",
    "    data = data / std\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Normalizando os dados. \n",
    "trainDataFilled = normalizeData(jnp.array(trainDataFilled.values))\n",
    "trainDataFilled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainDataDf = pd.DataFrame(trainData)\n",
    "\n",
    "# # Preenchendo valores faltantes com o rating médio do filme correspondente\n",
    "# dfMovieMean = trainDataDf.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "\n",
    "# # Preenchendo valores faltantes com a média dos ratings dados pelo usuário\n",
    "# dfUserMean = trainDataDf.apply(lambda x: x.fillna(x.mean()), axis=1)\n",
    "\n",
    "# # Preenchendo valroes faltantes com zeros\n",
    "# dfZeros = trainDataDf.fillna(0)\n",
    "\n",
    "# trainDataMovieMean = jnp.array(dfMovieMean)\n",
    "# trainDataUserMean = jnp.array(dfUserMean)\n",
    "# trainDataZeros = jnp.array(dfZeros)\n",
    "\n",
    "# print(\"DataFrame with column mean filled:\\n\", dfMovieMean.head(), '\\n')\n",
    "# print(\"DataFrame with row mean filled:\\n\", dfUserMean.head(), '\\n')\n",
    "# print(\"DataFrame with zeros filled:\\n\", dfZeros.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo as funções para implementação do SVD, KNN e PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(eigenvalues:jnp.ndarray, eigenvectors:jnp.ndarray) -> tuple[jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\" Reorders in descending order the eigenvalues and corresponding eigenvectors based on the eigenvectors values.\n",
    "\n",
    "    Args:\n",
    "        eigenvalues (jnp.ndarray): 1D array containing the eigenvalues.\n",
    "        eigenvectors (jnp.ndarray): 2D array cotaining eigenvectors as columns.\n",
    "\n",
    "    Returns:\n",
    "        tuple[jnp.ndarray, jnp.ndarray]: Reordered eigenvalues and eigenvectors.\n",
    "    \"\"\"\n",
    "    orderedIndices = jnp.argsort(eigenvalues, descending=True) \n",
    "    orderedEigenvalues = eigenvalues[orderedIndices] \n",
    "    orderedEigenvectors = eigenvectors[:, orderedIndices] \n",
    "\n",
    "    return orderedEigenvalues, orderedEigenvectors\n",
    "\n",
    "\n",
    "def svd(data:jnp.ndarray) -> Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\" From a data matrix, return its Singular Value Decomposition (SVD) \n",
    "    computed using the eigendecomposition of the data's covariance matrix.\n",
    "\n",
    "    Args:\n",
    "        data (jnp.ndarray): Rectangular matrix\n",
    "\n",
    "    Returns:\n",
    "        Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]: SVD of the data matrix, where data = U.S.V^T\n",
    "    \"\"\"\n",
    "\n",
    "    # Computing the data matrix's right-singular vectors, as well as the singular values\n",
    "    eigenvalues, rEigenvectors = jnp.linalg.eig(data.T @ data)\n",
    "    eigenvalues, rEigenvectors = reorder(eigenvalues, rEigenvectors)\n",
    "    Vt = jnp.real(rEigenvectors.T)    \n",
    "    S = jnp.real(eigenvalues ** (1/2))\n",
    "\n",
    "    # Computing the data matrix's left-singular vectors\n",
    "    eigenvalues, lEigenvectors = jnp.linalg.eig(data @ data.T)\n",
    "    eigenvalues, lEigenvectors = reorder(eigenvalues, lEigenvectors)\n",
    "    U = jnp.real(lEigenvectors)\n",
    "\n",
    "    \n",
    "    return U, S, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(data:jnp.ndarray, nbComponents:int, svd=True) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    A partir de um conjunto de dados, retorna a matriz de projeção para as k componentes principais.\n",
    "\n",
    "    Args:\n",
    "        data (jnp.ndaaray): Dados para reduzir dimensionalidade.\n",
    "        nbComponents (int): Número de componentes desejadas na projeção.\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: Matriz de projeção.\n",
    "    \"\"\"\n",
    "\n",
    "    covarianceMatrix = (1/len(data)) * data.T @ data\n",
    "    \n",
    "    if svd:\n",
    "        # Realizando a decomposição em valores singulares. U terá vetores coluna ortogonais.  \n",
    "        # A pricípio, o ordenamento não é necessário pois svd() já retorna os valores singulares ordenados.  \n",
    "        U, S, Ut = jax.scipy.linalg.svd(covarianceMatrix) \n",
    "        projectionMatrix = U[:, :nbComponents]\n",
    "    else:\n",
    "        # Decomposição a partir de autovalores e autovetores.\n",
    "        # Aqui, o ordenamento dos autovetores baseado nos autovalores é necessário.\n",
    "        eigenvalues, eigenvectors = jnp.linalg.eig(covarianceMatrix)  \n",
    "        indices = jnp.argsort(eigenvalues, descending=True)           \n",
    "        projectionMatrix = eigenvectors[:, indices]  \n",
    "        projectionMatrix = projectionMatrix[:, :nbComponents]\n",
    "   \n",
    "\n",
    "    return projectionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(xTrain:jnp.ndarray, yTrain:jnp.ndarray, xTest:jnp.ndarray, k:int, metric:Callable[[jnp.ndarray, jnp.ndarray], float]) -> jnp.ndarray:\n",
    "    \"\"\" Implementa a classificação de um conjunto de dados a partir do algoritmo de K-Nearest Neighbors (KNN).\n",
    "\n",
    "    Args:\n",
    "        xTrain (jnp.ndarray): Dados de treino\n",
    "        yTrain (jnp.ndarray): Labels para os dados de treino\n",
    "        xTest (jnp.ndarray): Dados de teste\n",
    "        k (int): Número de vizinhos mais próximos usados para a classificação.\n",
    "        metric (Callable): Função que calcula distância entre dois pontos.\n",
    "\n",
    "    Returns:\n",
    "        jnp.ndarray: Array contendo as predições realizadas para o conjunto de dados de teste xTest.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Implementação JAX-friendly do cálculo da matriz de distâncias para um conjunto de pontos de teste.\n",
    "    # O cálculo da matriz é feito vetorizando duas vezes a função de métrica, para calcular dois a dois\n",
    "    # as distâncias entre pontos de treino e de teste.\n",
    "    distances = jax.vmap(lambda train_point: jax.vmap(metric, in_axes=(None, 0))(train_point, xTest))(xTrain)\n",
    "\n",
    "    # Ordenando as distâncias entre pontos, e pegando os targets/labels dos k pontos mais próximos para cada ponto de treino\n",
    "    sorted_indices = jnp.argsort(distances, axis=0)\n",
    "    nearestNeighborsIndices = sorted_indices[:k, :]\n",
    "    nearestNeighbors = yTrain[nearestNeighborsIndices].astype(int)\n",
    "\n",
    "    # Contagem dos números de cada target presente na lista de vizinhos próximos e definição do target estimado para o ponto\n",
    "    # de teste baseado numa voto de maioria.\n",
    "    totalLabels = 3\n",
    "    targetCounts = jax.vmap(lambda neighbors: jnp.bincount(neighbors, minlength=totalLabels, length=3))(nearestNeighbors.T) \n",
    "    most_common_classes = jnp.argmax(targetCounts, axis=1)\n",
    "    \n",
    "    return most_common_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbComponents = 3\n",
    "# Realizando a decomposição em valores singulares. U terá vetores coluna ortogonais.  \n",
    "# A pricípio, o ordenamento não é necessário pois svd() já retorna os valores singulares ordenados.  \n",
    "U, S, Vt = jax.scipy.linalg.svd(dfZeros) \n",
    "projectionMatrix = U[:, :nbComponents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando a implementação da decomposição em valores principais a partir dos autovalores e autovetores da matriz de covariância dos dados.\n",
    "\n",
    "Aqui geramos uma matriz aleatória, calculamos seus valores e vetores principais, e comparamos com a implementação nativa do JAX para fins de checagem de sanidade. \n",
    "\n",
    "Vemos que a matrix ortogonal de vetores principais não é a mesma obtida pela implementação do JAX, porém isso acontece somente devido a uma inversão do sinal de alguns dos vetores. Nas matrizes U e Ut, isso se traduz respectivamente em uma inversão de sinal de colunas ou linhas especificas, o que não altera as propriedades matemáticas da nossa decomposição. Portanto, a menos de desvios numéricos, temos uma implementação equivalente feita a partir dos autovetores e autovalores da matriz de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os dados aleatórios para teste\n",
    "key = jax.random.PRNGKey(0)\n",
    "random_array = jax.random.uniform(key, (5, 4))\n",
    "data = random_array\n",
    "covarianceMatrix = (1/len(data)) * data.T @ data\n",
    "\n",
    "# Calculando a SVD usando dois métodos diferentes: implementação nativa e usando autovalores e autovetores\n",
    "U1, S1, Vt1 = jax.scipy.linalg.svd(covarianceMatrix) \n",
    "U2, S2, Vt2 = svd(covarianceMatrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparando U: \n",
      "[[-0.5625489   0.7061049  -0.26226145 -0.34084198]\n",
      " [-0.45437548 -0.49096245  0.43556333 -0.60231495]\n",
      " [-0.4274326  -0.50450015 -0.71912175  0.21364647]\n",
      " [-0.5425707   0.07649231  0.47367406  0.6894916 ]]\n",
      "[[ 0.56254894 -0.70610535  0.26226294  0.34084186]\n",
      " [ 0.4543755   0.4909616  -0.43556163  0.6023146 ]\n",
      " [ 0.42743263  0.5045007   0.71912086 -0.21364544]\n",
      " [ 0.54257077 -0.07649165 -0.4736765  -0.6894922 ]]\n",
      "\n",
      "\n",
      "Comparando Ut: \n",
      "[[-0.56254894 -0.4543754  -0.4274326  -0.5425706 ]\n",
      " [ 0.706105   -0.49096242 -0.50450003  0.07649231]\n",
      " [-0.26226142  0.43556345 -0.719122    0.47367418]\n",
      " [-0.340842   -0.60231483  0.21364635  0.6894918 ]]\n",
      "[[ 0.56254894  0.4543755   0.42743257  0.5425707 ]\n",
      " [-0.7061053   0.49096262  0.5044998  -0.07649182]\n",
      " [ 0.26226133 -0.435565    0.7191219  -0.47367254]\n",
      " [ 0.3408419   0.60231435 -0.21364391 -0.689493  ]]\n",
      "\n",
      "\n",
      "Comparando valores principais: \n",
      "[1.2094074  0.1760837  0.10692322 0.05494076]\n",
      "[1.2094078  0.17608385 0.10692321 0.05494073]\n"
     ]
    }
   ],
   "source": [
    "# Os dois arrays devem ser iguais, a menos de um sinal em cada coluna\n",
    "print(\"Comparando U: \")\n",
    "print(U1)\n",
    "print(U2)\n",
    "\n",
    "# Os dois arrays devem ser iguais, a menos de um sinal em cada linha\n",
    "print(\"\\n\\nComparando Ut: \")\n",
    "print(Vt1)\n",
    "print(Vt2)\n",
    "\n",
    "# Os valores principais devem ser exatamente iguais\n",
    "print(\"\\n\\nComparando valores principais: \")\n",
    "print(S1)\n",
    "print(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mo431",
   "language": "python",
   "name": "mo431"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
